{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the houseprices data from Thinkful's database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "housing_df = pd.read_sql_query('select * from houseprices',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mssubclass</th>\n",
       "      <th>mszoning</th>\n",
       "      <th>lotfrontage</th>\n",
       "      <th>lotarea</th>\n",
       "      <th>street</th>\n",
       "      <th>alley</th>\n",
       "      <th>lotshape</th>\n",
       "      <th>landcontour</th>\n",
       "      <th>utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>poolarea</th>\n",
       "      <th>poolqc</th>\n",
       "      <th>fence</th>\n",
       "      <th>miscfeature</th>\n",
       "      <th>miscval</th>\n",
       "      <th>mosold</th>\n",
       "      <th>yrsold</th>\n",
       "      <th>saletype</th>\n",
       "      <th>salecondition</th>\n",
       "      <th>saleprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  mssubclass mszoning  lotfrontage  lotarea street alley lotshape  \\\n",
       "0   1          60       RL         65.0     8450   Pave  None      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave  None      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave  None      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave  None      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave  None      IR1   \n",
       "\n",
       "  landcontour utilities  ... poolarea poolqc fence miscfeature miscval mosold  \\\n",
       "0         Lvl    AllPub  ...        0   None  None        None       0      2   \n",
       "1         Lvl    AllPub  ...        0   None  None        None       0      5   \n",
       "2         Lvl    AllPub  ...        0   None  None        None       0      9   \n",
       "3         Lvl    AllPub  ...        0   None  None        None       0      2   \n",
       "4         Lvl    AllPub  ...        0   None  None        None       0     12   \n",
       "\n",
       "  yrsold  saletype  salecondition  saleprice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.head()\n",
    "# question 1 is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Do data cleaning, exploratory data analysis, and feature engineering. You can use your previous work in this module. But make sure that your work is satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0.000000\n",
       "mssubclass        0.000000\n",
       "mszoning          0.000000\n",
       "lotfrontage      17.739726\n",
       "lotarea           0.000000\n",
       "street            0.000000\n",
       "alley            93.767123\n",
       "lotshape          0.000000\n",
       "landcontour       0.000000\n",
       "utilities         0.000000\n",
       "lotconfig         0.000000\n",
       "landslope         0.000000\n",
       "neighborhood      0.000000\n",
       "condition1        0.000000\n",
       "condition2        0.000000\n",
       "bldgtype          0.000000\n",
       "housestyle        0.000000\n",
       "overallqual       0.000000\n",
       "overallcond       0.000000\n",
       "yearbuilt         0.000000\n",
       "yearremodadd      0.000000\n",
       "roofstyle         0.000000\n",
       "roofmatl          0.000000\n",
       "exterior1st       0.000000\n",
       "exterior2nd       0.000000\n",
       "masvnrtype        0.547945\n",
       "masvnrarea        0.547945\n",
       "exterqual         0.000000\n",
       "extercond         0.000000\n",
       "foundation        0.000000\n",
       "                   ...    \n",
       "bedroomabvgr      0.000000\n",
       "kitchenabvgr      0.000000\n",
       "kitchenqual       0.000000\n",
       "totrmsabvgrd      0.000000\n",
       "functional        0.000000\n",
       "fireplaces        0.000000\n",
       "fireplacequ      47.260274\n",
       "garagetype        5.547945\n",
       "garageyrblt       5.547945\n",
       "garagefinish      5.547945\n",
       "garagecars        0.000000\n",
       "garagearea        0.000000\n",
       "garagequal        5.547945\n",
       "garagecond        5.547945\n",
       "paveddrive        0.000000\n",
       "wooddecksf        0.000000\n",
       "openporchsf       0.000000\n",
       "enclosedporch     0.000000\n",
       "threessnporch     0.000000\n",
       "screenporch       0.000000\n",
       "poolarea          0.000000\n",
       "poolqc           99.520548\n",
       "fence            80.753425\n",
       "miscfeature      96.301370\n",
       "miscval           0.000000\n",
       "mosold            0.000000\n",
       "yrsold            0.000000\n",
       "saletype          0.000000\n",
       "salecondition     0.000000\n",
       "saleprice         0.000000\n",
       "Length: 81, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.isnull().sum() * 100/housing_df.isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above list, we can see that a few of our features have many null values. For each feature missing more than 6% of its values, we will replace its nulls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lot Frontage is  “Linear feet of street connected to property\". Null values for this field come from properties that do not have this property, so a value of 0 can be used to replace Null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['lotfrontage'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Alley column lists the \"Type of alley access\", so the Null values for this column are from houses that do not have alleys. The Null values can be replaced with \"No\" so that later a dummy variable can be constructed if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['alley'].fillna('No',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fireplacequ lists the \"Fireplace quality\", so houses without fireplaces will have Null values. These Null values can be replaced with \"No\", so that a dummy variable can be constructed later if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['fireplacequ'].fillna('No',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poolqc lists \"Pool quality\", so houses that have no pool will have Null values. These Null values can be replaced with \"No\", so that a dummy variable can be constructed later if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['poolqc'].fillna('No',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fence lists \"Fence quality\", so houses that have no fences will have Null values. These Null values can be replaced with \"No\", so that a dummy variable can be constructed later if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['fence'].fillna('No',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miscfeature lists \"Miscellaneous feature not covered in other categories\", so there will be Null values for houses without features that need to be covered in this column. These Null values can be replaced with \"No\", so that a dummy variable can be constructed later if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['miscfeature'].fillna('No',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From previous work on this dataset, we know that we can make a reliable model using certain features. These features will be used below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mszoning is an important feature, but it is categorical, so dummy variables must be constructed. Similarly, street is useful but categorical, so dummy variables must be constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.concat([housing_df,pd.get_dummies(housing_df.mszoning, prefix=\"mszoning\", drop_first=True)], axis=1)\n",
    "housing_df = pd.concat([housing_df,pd.get_dummies(housing_df.street, prefix=\"street\", drop_first=True)], axis=1)\n",
    "dummy_column_names = list(pd.get_dummies(housing_df.mszoning, prefix=\"mszoning\", drop_first=True).columns)\n",
    "dummy_column_names = dummy_column_names + list(pd.get_dummies(housing_df.street, prefix=\"street\", drop_first=True).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two new variables will be created from the already-existent variables in the dataset. totalsf is the sum of the first floor, second floor, and basement square footage. int_over_sf is constructed from totalsf multiplied by overallqual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['totalsf'] = housing_df['totalbsmtsf'] + housing_df['firstflrsf'] + housing_df['secondflrsf']\n",
    "\n",
    "housing_df['int_over_sf'] = housing_df['totalsf'] * housing_df['overallqual']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable, saleprice, is not normally distributed, so using a log transform will improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is the target variable\n",
    "# log transform the target variable to make it more normal\n",
    "Y = np.log1p(housing_df['saleprice'])\n",
    "# X is the feature set\n",
    "X = housing_df[['overallqual', 'grlivarea', 'garagecars', 'garagearea', 'totalsf', 'int_over_sf'] + dummy_column_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exploratory phase can now be concluded. For the model, overallqual, grlivarea, garagecars, garagearea, totalsf, int_over_sf, the mszoning dummies created above, and the street dummies created above will be used as predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Now, split your data into train and test sets where 20% of the data resides in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   520.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 04 Dec 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:06:00</td>     <th>  Log-Likelihood:    </th> <td>  463.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>  -904.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1156</td>      <th>  BIC:               </th> <td>  -843.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>    9.9162</td> <td>    0.102</td> <td>   97.518</td> <td> 0.000</td> <td>    9.717</td> <td>   10.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overallqual</th> <td>    0.1893</td> <td>    0.009</td> <td>   20.123</td> <td> 0.000</td> <td>    0.171</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grlivarea</th>   <td>  9.58e-05</td> <td> 1.89e-05</td> <td>    5.074</td> <td> 0.000</td> <td> 5.88e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagecars</th>  <td>    0.0779</td> <td>    0.015</td> <td>    5.244</td> <td> 0.000</td> <td>    0.049</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagearea</th>  <td>    0.0001</td> <td> 5.04e-05</td> <td>    2.132</td> <td> 0.033</td> <td> 8.57e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totalsf</th>     <td>    0.0003</td> <td> 2.58e-05</td> <td>   11.139</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>int_over_sf</th> <td>-2.572e-05</td> <td> 3.02e-06</td> <td>   -8.526</td> <td> 0.000</td> <td>-3.16e-05</td> <td>-1.98e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_FV</th> <td>    0.3911</td> <td>    0.065</td> <td>    6.055</td> <td> 0.000</td> <td>    0.264</td> <td>    0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_RH</th> <td>    0.2650</td> <td>    0.074</td> <td>    3.593</td> <td> 0.000</td> <td>    0.120</td> <td>    0.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_RL</th> <td>    0.3879</td> <td>    0.060</td> <td>    6.481</td> <td> 0.000</td> <td>    0.270</td> <td>    0.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_RM</th> <td>    0.2155</td> <td>    0.061</td> <td>    3.556</td> <td> 0.000</td> <td>    0.097</td> <td>    0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>street_Pave</th> <td>   -0.0556</td> <td>    0.075</td> <td>   -0.744</td> <td> 0.457</td> <td>   -0.202</td> <td>    0.091</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>350.711</td> <th>  Durbin-Watson:     </th> <td>   1.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2714.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.167</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.094</td>  <th>  Cond. No.          </th> <td>5.33e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.33e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.832\n",
       "Model:                            OLS   Adj. R-squared:                  0.831\n",
       "Method:                 Least Squares   F-statistic:                     520.9\n",
       "Date:                Wed, 04 Dec 2019   Prob (F-statistic):               0.00\n",
       "Time:                        07:06:00   Log-Likelihood:                 463.99\n",
       "No. Observations:                1168   AIC:                            -904.0\n",
       "Df Residuals:                    1156   BIC:                            -843.2\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const           9.9162      0.102     97.518      0.000       9.717      10.116\n",
       "overallqual     0.1893      0.009     20.123      0.000       0.171       0.208\n",
       "grlivarea     9.58e-05   1.89e-05      5.074      0.000    5.88e-05       0.000\n",
       "garagecars      0.0779      0.015      5.244      0.000       0.049       0.107\n",
       "garagearea      0.0001   5.04e-05      2.132      0.033    8.57e-06       0.000\n",
       "totalsf         0.0003   2.58e-05     11.139      0.000       0.000       0.000\n",
       "int_over_sf -2.572e-05   3.02e-06     -8.526      0.000   -3.16e-05   -1.98e-05\n",
       "mszoning_FV     0.3911      0.065      6.055      0.000       0.264       0.518\n",
       "mszoning_RH     0.2650      0.074      3.593      0.000       0.120       0.410\n",
       "mszoning_RL     0.3879      0.060      6.481      0.000       0.270       0.505\n",
       "mszoning_RM     0.2155      0.061      3.556      0.000       0.097       0.334\n",
       "street_Pave    -0.0556      0.075     -0.744      0.457      -0.202       0.091\n",
       "==============================================================================\n",
       "Omnibus:                      350.711   Durbin-Watson:                   1.876\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2714.386\n",
       "Skew:                          -1.167   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.094   Cond. No.                     5.33e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.33e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 465)\n",
    "\n",
    "results = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model, using OLS, has an R-Squared of .832 AIC of -904, and BIC of -843. 83% of the variance in our data is explained by this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build several linear regression models including Lasso, Ridge, or ElasticNet and train them in the training set. Use k-fold cross-validation to select the best hyperparameters if your models include one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 0.0001\n",
      "R-squared of the model in training set is: 0.831939428704242\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.8226434437869412\n",
      "Mean absolute error of the prediction is: 0.12624310826908416\n",
      "Mean squared error of the prediction is: 0.029573434037677038\n",
      "Root mean squared error of the prediction is: 0.17196928225028166\n",
      "Mean absolute percentage error of the prediction is: 1.0552354946577736\n"
     ]
    }
   ],
   "source": [
    "# construct a range of alpha values to be used in the models.\n",
    "# the best alpha value for each model will be reported.\n",
    "alphas = [np.power(10.0,p) for p in np.arange(-10,40,1)]\n",
    "\n",
    "\n",
    "# round 'em up\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5)\n",
    "\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = lasso_cv.predict(X_train)\n",
    "y_preds_test = lasso_cv.predict(X_test)\n",
    "\n",
    "print(f\"Best alpha value is: {lasso_cv.alpha_}\")\n",
    "print(f\"R-squared of the model in training set is: {lasso_cv.score(X_train, y_train)}\")\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(f\"R-squared of the model in test set is: {lasso_cv.score(X_test, y_test)}\")\n",
    "print(f\"Mean absolute error of the prediction is: {mean_absolute_error(y_test, y_preds_test)}\")\n",
    "print(f\"Mean squared error of the prediction is: {mse(y_test, y_preds_test)}\")\n",
    "print(f\"Root mean squared error of the prediction is: {rmse(y_test, y_preds_test)}\")\n",
    "print(f\"Mean absolute percentage error of the prediction is: {np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 1.0\n",
      "R-squared of the model in training set is: 0.8316364867222636\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.8203050076234274\n",
      "Mean absolute error of the prediction is: 0.1267363733974108\n",
      "Mean squared error of the prediction is: 0.029963358092979037\n",
      "Root mean squared error of the prediction is: 0.1730992723640947\n",
      "Mean absolute percentage error of the prediction is: 1.0596941230310684\n"
     ]
    }
   ],
   "source": [
    "# ruffles have ridges\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
    "\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = ridge_cv.predict(X_train)\n",
    "y_preds_test = ridge_cv.predict(X_test)\n",
    "\n",
    "print(f\"Best alpha value is: {ridge_cv.alpha_}\")\n",
    "print(f\"R-squared of the model in training set is: {ridge_cv.score(X_train, y_train)}\")\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(f\"R-squared of the model in test set is: {ridge_cv.score(X_test, y_test)}\")\n",
    "print(f\"Mean absolute error of the prediction is: {mean_absolute_error(y_test, y_preds_test)}\")\n",
    "print(f\"Mean squared error of the prediction is: {mse(y_test, y_preds_test)}\")\n",
    "print(f\"Root mean squared error of the prediction is: {rmse(y_test, y_preds_test)}\")\n",
    "print(f\"Mean absolute percentage error of the prediction is: {np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 0.001\n",
      "R-squared of the model in training set is: 0.8299654806803803\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.8149185869526183\n",
      "Mean absolute error of the prediction is: 0.12770726087011366\n",
      "Mean squared error of the prediction is: 0.03086152030253385\n",
      "Root mean squared error of the prediction is: 0.17567447254092966\n",
      "Mean absolute percentage error of the prediction is: 1.0685444897303116\n"
     ]
    }
   ],
   "source": [
    "elasticnet_cv = ElasticNetCV(alphas=alphas, cv=5)\n",
    "\n",
    "elasticnet_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = elasticnet_cv.predict(X_train)\n",
    "y_preds_test = elasticnet_cv.predict(X_test)\n",
    "\n",
    "print(f\"Best alpha value is: {elasticnet_cv.alpha_}\")\n",
    "print(f\"R-squared of the model in training set is: {elasticnet_cv.score(X_train, y_train)}\")\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(f\"R-squared of the model in test set is: {elasticnet_cv.score(X_test, y_test)}\")\n",
    "print(f\"Mean absolute error of the prediction is: {mean_absolute_error(y_test, y_preds_test)}\")\n",
    "print(f\"Mean squared error of the prediction is: {mse(y_test, y_preds_test)}\")\n",
    "print(f\"Root mean squared error of the prediction is: {rmse(y_test, y_preds_test)}\")\n",
    "print(f\"Mean absolute percentage error of the prediction is: {np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate your best model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error of the prediction is: 0.12570372872853813\n",
      "Mean squared error of the prediction is: 0.029192121871305193\n",
      "Root mean squared error of the prediction is: 0.17085702172080958\n",
      "Mean absolute percentage error of the prediction is: 1.0503577667818464\n"
     ]
    }
   ],
   "source": [
    "# making predictions\n",
    "y_preds = results.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Mean absolute error of the prediction is: {mean_absolute_error(y_test, y_preds)}\")\n",
    "print(f\"Mean squared error of the prediction is: {mse(y_test, y_preds)}\")\n",
    "print(f\"Root mean squared error of the prediction is: {rmse(y_test, y_preds)}\")\n",
    "print(f\"Mean absolute percentage error of the prediction is: {np.mean(np.abs((y_test - y_preds) / y_test)) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the new models constructed above, it can be seen that the OLS model performs better than the new models. The original OLS model has an R-Squared value of .832, which is higher than the R-Squared values found in all of the new models. Moreover, all of the error values in the OLS model are lower than the error values for the new models. Lower error values indicate better model performance, so on the basis of these metrics, the OLS model can be selected over the other models that were constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. So far, you have only used the features in the dataset. However, house prices can be affected by many factors like economic activity and the interest rates at the time they are sold. So, try to find some useful factors that are not included in the dataset. Integrate these factors into your model and assess the prediction performance of your model. Discuss the implications of adding these external variables into your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of investigation, interest rates will be added to the initial dataset. Before the rates can be added, the dataset's timespan must be determined, because interest rates change multiple times a month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.yrsold.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.yrsold.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df[housing_df['yrsold']==2010].mosold.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df[housing_df['yrsold']==2006].mosold.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has information from January of 2006 to July of 2010. The average monthly interest rate will be added to the dataset so that its effect on housing prices can be investigated. Adding this variable to our model will hopefully make it more accurate. If interest rate is highly correlated with another variable already in the model, the model may become less accurate. Additionally, since our data only covers the period from 2006 to 2010 - a time that saw great economic turmoil in the United States - we may not be seeing a completely accurate picture of either interest rates or housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['interest'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==1),'interest'] = 6.15\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==2),'interest'] = 6.25\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==3),'interest'] = 6.32\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==4),'interest'] = 6.51\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==5),'interest'] = 6.60\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==6),'interest'] = 6.68\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==7),'interest'] = 6.76\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==8),'interest'] = 6.52\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==9),'interest'] = 6.40\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==10),'interest'] = 6.36\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==11),'interest'] = 6.24\n",
    "housing_df.loc[(housing_df['yrsold']==2006) & (housing_df['mosold']==12),'interest'] = 6.14\n",
    "\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==1),'interest'] = 6.22\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==2),'interest'] = 6.29\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==3),'interest'] = 6.16\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==4),'interest'] = 6.18\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==5),'interest'] = 6.26\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==6),'interest'] = 6.66\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==7),'interest'] = 6.70\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==8),'interest'] = 6.57\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==9),'interest'] = 6.38\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==10),'interest'] = 6.38\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==11),'interest'] = 6.21\n",
    "housing_df.loc[(housing_df['yrsold']==2007) & (housing_df['mosold']==12),'interest'] = 6.10\n",
    "\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==1),'interest'] = 5.76\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==2),'interest'] = 5.92\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==3),'interest'] = 5.97\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==4),'interest'] = 5.92\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==5),'interest'] = 6.04\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==6),'interest'] = 6.32\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==7),'interest'] = 6.43\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==8),'interest'] = 6.48\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==9),'interest'] = 6.04\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==10),'interest'] = 6.20\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==11),'interest'] = 6.09\n",
    "housing_df.loc[(housing_df['yrsold']==2008) & (housing_df['mosold']==12),'interest'] = 5.29\n",
    "\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==1),'interest'] = 5.05\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==2),'interest'] = 5.13\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==3),'interest'] = 5.00\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==4),'interest'] = 4.81\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==5),'interest'] = 4.86\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==6),'interest'] = 5.42\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==7),'interest'] = 5.22\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==8),'interest'] = 5.19\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==9),'interest'] = 5.06\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==10),'interest'] = 4.95\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==11),'interest'] = 4.88\n",
    "housing_df.loc[(housing_df['yrsold']==2009) & (housing_df['mosold']==12),'interest'] = 4.93\n",
    "\n",
    "housing_df.loc[(housing_df['yrsold']==2010) & (housing_df['mosold']==1),'interest'] = 5.03\n",
    "housing_df.loc[(housing_df['yrsold']==2010) & (housing_df['mosold']==2),'interest'] = 4.99\n",
    "housing_df.loc[(housing_df['yrsold']==2010) & (housing_df['mosold']==3),'interest'] = 4.97\n",
    "housing_df.loc[(housing_df['yrsold']==2010) & (housing_df['mosold']==4),'interest'] = 5.10\n",
    "housing_df.loc[(housing_df['yrsold']==2010) & (housing_df['mosold']==5),'interest'] = 4.89\n",
    "housing_df.loc[(housing_df['yrsold']==2010) & (housing_df['mosold']==6),'interest'] = 4.74\n",
    "housing_df.loc[(housing_df['yrsold']==2010) & (housing_df['mosold']==7),'interest'] = 4.56\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is the target variable\n",
    "# log transform the target variable to make it more normal\n",
    "Y = np.log1p(housing_df['saleprice'])\n",
    "# X is the feature set\n",
    "X = housing_df[['overallqual', 'grlivarea', 'garagecars', 'garagearea', 'totalsf', 'int_over_sf', 'interest'] + dummy_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   477.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 04 Dec 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:51:20</td>     <th>  Log-Likelihood:    </th> <td>  464.71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>  -903.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1155</td>      <th>  BIC:               </th> <td>  -837.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>    9.8684</td> <td>    0.109</td> <td>   90.266</td> <td> 0.000</td> <td>    9.654</td> <td>   10.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overallqual</th> <td>    0.1890</td> <td>    0.009</td> <td>   20.076</td> <td> 0.000</td> <td>    0.171</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grlivarea</th>   <td> 9.536e-05</td> <td> 1.89e-05</td> <td>    5.051</td> <td> 0.000</td> <td> 5.83e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagecars</th>  <td>    0.0777</td> <td>    0.015</td> <td>    5.233</td> <td> 0.000</td> <td>    0.049</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garagearea</th>  <td>    0.0001</td> <td> 5.04e-05</td> <td>    2.139</td> <td> 0.033</td> <td> 8.94e-06</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totalsf</th>     <td>    0.0003</td> <td> 2.58e-05</td> <td>   11.112</td> <td> 0.000</td> <td>    0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>int_over_sf</th> <td>-2.561e-05</td> <td> 3.02e-06</td> <td>   -8.485</td> <td> 0.000</td> <td>-3.15e-05</td> <td>-1.97e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interest</th>    <td>    0.0083</td> <td>    0.007</td> <td>    1.187</td> <td> 0.235</td> <td>   -0.005</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_FV</th> <td>    0.3922</td> <td>    0.065</td> <td>    6.072</td> <td> 0.000</td> <td>    0.265</td> <td>    0.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_RH</th> <td>    0.2640</td> <td>    0.074</td> <td>    3.581</td> <td> 0.000</td> <td>    0.119</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_RL</th> <td>    0.3880</td> <td>    0.060</td> <td>    6.483</td> <td> 0.000</td> <td>    0.271</td> <td>    0.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mszoning_RM</th> <td>    0.2153</td> <td>    0.061</td> <td>    3.554</td> <td> 0.000</td> <td>    0.096</td> <td>    0.334</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>street_Pave</th> <td>   -0.0539</td> <td>    0.075</td> <td>   -0.722</td> <td> 0.471</td> <td>   -0.201</td> <td>    0.093</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>350.606</td> <th>  Durbin-Watson:     </th> <td>   1.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2728.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.165</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.116</td>  <th>  Cond. No.          </th> <td>5.42e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.42e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.832\n",
       "Model:                            OLS   Adj. R-squared:                  0.831\n",
       "Method:                 Least Squares   F-statistic:                     477.8\n",
       "Date:                Wed, 04 Dec 2019   Prob (F-statistic):               0.00\n",
       "Time:                        07:51:20   Log-Likelihood:                 464.71\n",
       "No. Observations:                1168   AIC:                            -903.4\n",
       "Df Residuals:                    1155   BIC:                            -837.6\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const           9.8684      0.109     90.266      0.000       9.654      10.083\n",
       "overallqual     0.1890      0.009     20.076      0.000       0.171       0.207\n",
       "grlivarea    9.536e-05   1.89e-05      5.051      0.000    5.83e-05       0.000\n",
       "garagecars      0.0777      0.015      5.233      0.000       0.049       0.107\n",
       "garagearea      0.0001   5.04e-05      2.139      0.033    8.94e-06       0.000\n",
       "totalsf         0.0003   2.58e-05     11.112      0.000       0.000       0.000\n",
       "int_over_sf -2.561e-05   3.02e-06     -8.485      0.000   -3.15e-05   -1.97e-05\n",
       "interest        0.0083      0.007      1.187      0.235      -0.005       0.022\n",
       "mszoning_FV     0.3922      0.065      6.072      0.000       0.265       0.519\n",
       "mszoning_RH     0.2640      0.074      3.581      0.000       0.119       0.409\n",
       "mszoning_RL     0.3880      0.060      6.483      0.000       0.271       0.505\n",
       "mszoning_RM     0.2153      0.061      3.554      0.000       0.096       0.334\n",
       "street_Pave    -0.0539      0.075     -0.722      0.471      -0.201       0.093\n",
       "==============================================================================\n",
       "Omnibus:                      350.606   Durbin-Watson:                   1.876\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2728.044\n",
       "Skew:                          -1.165   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.116   Cond. No.                     5.42e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.42e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 465)\n",
    "\n",
    "results = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error of the prediction is: 0.12533295688787052\n",
      "Mean squared error of the prediction is: 0.028969043863888252\n",
      "Root mean squared error of the prediction is: 0.17020294904580313\n",
      "Mean absolute percentage error of the prediction is: 1.047293096836631\n"
     ]
    }
   ],
   "source": [
    "# making predictions\n",
    "y_preds = results.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Mean absolute error of the prediction is: {mean_absolute_error(y_test, y_preds)}\")\n",
    "print(f\"Mean squared error of the prediction is: {mse(y_test, y_preds)}\")\n",
    "print(f\"Root mean squared error of the prediction is: {rmse(y_test, y_preds)}\")\n",
    "print(f\"Mean absolute percentage error of the prediction is: {np.mean(np.abs((y_test - y_preds) / y_test)) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition of interest to the model has not improved the model by a large margin. The variable itself does not add a statistically significant amount of information to the model (p = .235), so it can be dropped without negatively affecting the model. The R-Squared in this model is the same as the R-Squared from the initial OLS model (.832), but the error metrics for the new model have gotten lower, indicating a slight increase in predictive performance. Altogether, it is clear that, unfortunately, the addition of interest rate data to the model does not significantly improve the model's power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
